Facebook lets people running groups at the social network use artificial intelligence to block misinformation. SAN FRANCISCO - Facebook on Wednesday began letting groups automatically reject posts identified as containing false information, taking aim at a part of the massive network that has drawn particular concern from misinformation watchdogs. More than 1.8 billion people per month use Facebook Groups, which allow members to gather around topics ranging from parenting to politics. Yet critics have said the groups are ripe targets for the spread of misleading or false information by having sometimes large audiences of like-minded users organized on a particular topic. Administrators of "groups" at the leading social network can opt to have software automatically reject incoming posts showcasing information found to be false by third-party fact-checkers, Facebook App communities vice president Maria Smith said. Groups were once touted by chief executive Mark Zuckerberg as a way to build more intimate communities at the world-spanning social network by providing online spaces for users to connect based on hobbies, endeavors, or other interests. "Our research shows, those same features — privacy and community — are often exploited by bad actors, foreign and domestic, to spread false information and conspiracies," disinformation researchers Nina Jankowicz and Cindy Otis wrote in a Wired opinion piece in 2020. Facebook has long been under heavy pressure to prevent its platform from being used to spread misinformation on topics from Russia's invasion of Ukraine to the Covid-19 pandemic and elections. The platform on Wednesday also updated a "suspend" tool that administrators can use to temporarily stop selected members from posting, commenting or otherwise taking part in a group. For groups seeking to incorporate new members, Facebook added the ability to promote them using email or QR codes, Smith said. AFP currently works with Facebook's fact checking program in more than 80 countries and 24 languages. Under the programme, which started in December 2016, Facebook pays to use fact checks from around 80 organizations, including media outlets and specialized fact checkers, on its platform, WhatsApp and on Instagram.  